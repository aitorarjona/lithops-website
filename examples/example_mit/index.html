<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  
  <link rel="shortcut icon" href="../../img/favicon.ico">
  <title>Lithops Moments in Time dataset example - Lithops</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700" />

  <link rel="stylesheet" href="../../css/theme.css" />
  <link rel="stylesheet" href="../../css/theme_extra.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" />
  
  <script>
    // Current page data
    var mkdocs_page_name = "Lithops Moments in Time dataset example";
    var mkdocs_page_input_path = "examples/example_mit.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../../js/jquery-2.1.1.min.js" defer></script>
  <script src="../../js/modernizr-2.8.3.min.js" defer></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
        <a href="../.." class="icon icon-home"> Lithops</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../getting-started/">Getting started</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">1. Lithops design overview</span></p>
                <ul>
                    <li class="toctree-l1"><a class="" href="https://github.com/lithops-cloud/lithops/blob/master/docs/design.md">Design overview</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">2. Supported Clouds</span></p>
                <ul>
                    <li class="toctree-l1"><a class="" href="https://github.com/lithops-cloud/lithops/blob/master/docs/supported_clouds.md">Supported Clouds</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">3. High-level Compute and Storage APIs</span></p>
                <ul>
                    <li class="toctree-l1"><a class="" href="https://github.com/lithops-cloud/lithops/blob/master/docs/api_futures.md">Futures API</a>
                    </li>
                    <li class="toctree-l1"><a class="" href="https://github.com/lithops-cloud/lithops/blob/master/docs/api_multiprocessing.md">Multiprocessing API</a>
                    </li>
                    <li class="toctree-l1"><a class="" href="https://github.com/lithops-cloud/lithops/blob/master/docs/api_storage.md">Storage API</a>
                    </li>
                    <li class="toctree-l1"><a class="" href="https://github.com/lithops-cloud/lithops/blob/master/docs/api_storage_os.md">Storage OS API</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">4. Execution Modes</span></p>
                <ul>
                    <li class="toctree-l1"><a class="" href="https://github.com/lithops-cloud/lithops/blob/master/docs/mode_localhost.md">Localhost mode</a>
                    </li>
                    <li class="toctree-l1"><a class="" href="https://github.com/lithops-cloud/lithops/blob/master/docs/mode_serverless.md">Serverless mode</a>
                    </li>
                    <li class="toctree-l1"><a class="" href="https://github.com/lithops-cloud/lithops/blob/master/docs/mode_standalone.md">Standalone mode</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">5. Functions design and parameters</span></p>
                <ul>
                    <li class="toctree-l1"><a class="" href="https://github.com/lithops-cloud/lithops/blob/master/docs/functions.md">Functions overview</a>
                    </li>
                    <li class="toctree-l1"><a class="" href="https://github.com/lithops-cloud/lithops/blob/master/docs/functions.md#reserved-parameters">Reserved parameters</a>
                    </li>
                    <li class="toctree-l1"><a class="" href="https://github.com/lithops-cloud/lithops/blob/master/docs/functions.md#parameters-in-the-call_async-method">Parameters format for a single call</a>
                    </li>
                    <li class="toctree-l1"><a class="" href="https://github.com/lithops-cloud/lithops/blob/master/docs/functions.md#parameters-in-the-map-and-map_reduce-methods">Parameters format for a map call</a>
                    </li>
                    <li class="toctree-l1"><a class="" href="https://github.com/lithops-cloud/lithops/blob/master/docs/functions.md#common-parameters-across-functions-invocations">Common parameters across functions</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">6. Lithops for big data analytics</span></p>
                <ul>
                    <li class="toctree-l1"><a class="" href="https://github.com/lithops-cloud/lithops/blob/master/docs/data_processing.md">Overview</a>
                    </li>
                    <li class="toctree-l1"><a class="" href="https://github.com/lithops-cloud/lithops/blob/master/docs/data_processing.md#processing-data-from-a-cloud-object-storage-service">Processing data from a cloud object store</a>
                    </li>
                    <li class="toctree-l1"><a class="" href="https://github.com/lithops-cloud/lithops/blob/master/docs/data_processing.md#processing-data-from-public-urls">Processing data from public URLs</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">7. Run Lithops on Jupyter notebooks</span></p>
                <ul>
                    <li class="toctree-l1"><a class="" href="https://github.com/lithops-cloud/lithops/blob/master/examples/hello_world.ipynb">Lithops on Jupyter notebooks</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">8. Execute Airflow workflows using Lithops</span></p>
                <ul>
                    <li class="toctree-l1"><a class="" href="https://github.com/lithops-cloud/airflow-plugin">Airflow plugin</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">9. Lithops end-to-end Applications</span></p>
                <ul>
                    <li class="toctree-l1"><a class="" href="https://github.com/lithops-cloud/applications">Lithops applications</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">10. Build and manage custom runtimes to run the functions</span></p>
                <ul>
                    <li class="toctree-l1"><a class="" href="https://github.com/lithops-cloud/applications">Custom runtime docs</a>
                    </li>
                </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../..">Lithops</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../..">Docs</a> &raquo;</li>
    
      
    
    <li>Lithops Moments in Time dataset example</li>
    <li class="wy-breadcrumbs-aside">
      
        <a href="https://github.com/lithops-cloud/lithops/edit/master/docs/examples/example_mit.md"> Edit on lithops-cloud/lithops</a>
      
    </li>
  </ul>
  
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h2 id="lithops-moments-in-time-dataset-example">Lithops Moments in Time dataset example<a class="headerlink" href="#lithops-moments-in-time-dataset-example" title="Permanent link">&para;</a></h2>
<h3 id="videoimage-prediction">Video/image prediction<a class="headerlink" href="#videoimage-prediction" title="Permanent link">&para;</a></h3>
<p>In <a href="https://github.com/cloudbutton/examples/blob/master/momentsintime/example_mit.ipynb">this notebook</a> we will process video clips from the MiT dataset at scale with Lithops
by predicting the actions with a pretrained ResNet50 model and then counting how many
occurrences of each category have been predicted.</p>
<pre class="codehilite"><code class="language-python">import time
import builtins
import torch.optim
import torch.nn.parallel
from torch import save, load
from torch.nn import functional as F

from utils import extract_frames
from models import load_model, load_transform, load_categories

from lithops.multiprocessing import Pool, Queue
from lithops.multiprocessing.util import get_uuid
</code></pre>

<h4 id="backends">Backends<a class="headerlink" href="#backends" title="Permanent link">&para;</a></h4>
<p>The same program can be run in a local environtment with processes or executed by
functions in the cloud. After we choose a backend, only a few file locations must
be changed. In this example we will be using the cloud functions backend.</p>
<p>We will be using a custom runtime for our functions which has torch, torchvision,
ffmpeg and opencv-python modules already installed.
We will store the pretrained weights in the cloud so that functions can access it.
Then, after functions get the models weights they will start preprocessing input
videos and inferring them one by one.</p>
<p>Later in this notebook, we will see a little improvement detail to this process.  </p>
<pre class="codehilite"><code class="language-python">LOCAL_EXEC = False
</code></pre>

<pre class="codehilite"><code class="language-python">INPUT_DATA_DIR = 'momentsintime/input_data'

if LOCAL_EXEC:
    import os
    from builtins import open
    initargs = {
        'backend': 'localhost',
        'storage_backend': 'localhost'
        }
    weights_location = '/dev/shm/model_weights'
    INPUT_DATA_DIR = os.path.abspath(INPUT_DATA_DIR)

else:
    from lithops.cloud_proxy import os, open
    initargs = {
        'backend': 'ibm_cf',
        'storage_backend': 'ibm_cos',
        'runtime': 'dhak/pywren-runtime-pytorch:3.6',
        'runtime_memory': 2048
        }
    weights_location = 'momentsintime/models/model_weights'
</code></pre>

<pre class="codehilite"><code class="language-python">video_locations = [os.path.join(INPUT_DATA_DIR, name) for name in os.listdir(INPUT_DATA_DIR)]
</code></pre>

<p>As you can see, we have masked the <code>open</code> function and <code>os</code> module with a proxy
to manage files from the cloud transparently.<br />
We will use <code>builtins.open</code> from now on to explicitly access a local file as some accesses have to occur in the very same machine.</p>
<h4 id="download-pretrained-resnet50-model-weights-and-save-them-in-a-directory-accessible-by-all-functions-weights_location">Download pretrained ResNet50 model weights and save them in a directory accessible by all functions (<code>weights_location</code>)<a class="headerlink" href="#download-pretrained-resnet50-model-weights-and-save-them-in-a-directory-accessible-by-all-functions-weights_location" title="Permanent link">&para;</a></h4>
<pre class="codehilite"><code class="language-python">ROOT_URL = 'http://moments.csail.mit.edu/moments_models'
WEIGHTS_FILE = 'moments_RGB_resnet50_imagenetpretrained.pth.tar'

if not os.access(WEIGHTS_FILE, os.R_OK):
    os.system('wget ' + '/'.join([ROOT_URL, WEIGHTS_FILE]))

with builtins.open(WEIGHTS_FILE, 'rb') as f_in:
    weights = f_in.read()
with open(weights_location, 'wb') as f_out:
    f_out.write(weights)
</code></pre>

<h4 id="video-prediction-and-reduce-function-code">Video prediction and reduce function code<a class="headerlink" href="#video-prediction-and-reduce-function-code" title="Permanent link">&para;</a></h4>
<pre class="codehilite"><code class="language-python">NUM_SEGMENTS = 16

# Get dataset categories
categories = load_categories()

# Load the video frame transform
transform = load_transform()

def predict_videos(queue, video_locations):
    with open(weights_location, 'rb') as f:
        model = load_model(f)
    model.eval()

    results = []
    local_video_loc = 'video_to_predict_{}.mp4'.format(get_uuid())

    for video_loc in video_locations:
        start = time.time()
        with open(video_loc, 'rb') as f_in:
            with builtins.open(local_video_loc, 'wb') as f_out:
                f_out.write(f_in.read())

        # Obtain video frames
        frames = extract_frames(local_video_loc, NUM_SEGMENTS)

        # Prepare input tensor [num_frames, 3, 224, 224]
        input_v = torch.stack([transform(frame) for frame in frames])

        # Make video prediction
        with torch.no_grad():
            logits = model(input_v)
            h_x = F.softmax(logits, 1).mean(dim=0)
            probs, idx = h_x.sort(0, True)

        # Output the prediction
        result = dict(key=video_loc)
        result['prediction'] = (idx[0], round(float(probs[0]), 5))
        result['iter_duration'] = time.time() - start
        results.append(result)
    queue.put(results)

# Counts how many predictions of each category have been made
def reduce(queue, n):
    pred_x_categ = {}
    for categ in categories:
        pred_x_categ[categ] = 0

    checkpoint = 0.2
    res_count = 0

    for i in range(n):
        results = queue.get()
        res_count += len(results)
        for res in results:
            idx, prob = res['prediction']
            pred_x_categ[categories[idx]] += 1

        # print progress
        if i &gt;= (N * checkpoint):
            print('Processed {} results.'.format(res_count))
            checkpoint += 0.2

    return pred_x_categ
</code></pre>

<h4 id="map-functions">Map functions<a class="headerlink" href="#map-functions" title="Permanent link">&para;</a></h4>
<p>Similar to the <code>multiprocessing</code> module API, we use a Pool to map the video keys
across n workers (concurrency). However, we do not have to instantiate a Pool of
n workers <em>specificly</em>, it is the map function that will invoke as many workers according
to the length of the list.</p>
<pre class="codehilite"><code class="language-python">CONCURRENCY = 1000
</code></pre>

<pre class="codehilite"><code class="language-python">queue = Queue()
pool = Pool(initargs=initargs)

# Slice data keys
N = min(CONCURRENCY, len(video_locations))
iterable = [(queue, video_locations[n::CONCURRENCY]) 
            for n in range(N)]

# Map and reduce on the go
start = time.time()
pool.map_async(func=predict_videos, iterable=iterable)
pred_x_categ = reduce(queue, N)
end = time.time()

print('\nDone.')
print('Videos processed:', len(video_locations))
print('Total duration:', round(end - start, 2), 'sec\n')

for categ, count in pred_x_categ.items():
    if count != 0:
        print('{}: {}'.format(categ, count))
</code></pre>

<hr />
<h3 id="performance-improvement">Performance improvement<a class="headerlink" href="#performance-improvement" title="Permanent link">&para;</a></h3>
<p>Now, since we know every function will have to pull the model weights from
the cloud storage, we can actually pack these weights with the runtime image
and reduce the start-up cost substantially.</p>
<pre class="codehilite"><code class="language-python">initargs['runtime'] = 'dhak/pywren-runtime-resnet'
weights_location = '/momentsintime/model_weights'
</code></pre>

<pre class="codehilite"><code class="language-python">def predict_videos(queue, video_locations):
    # force local file access on new weights_location
    with builtins.open(weights_location, 'rb') as f:
        model = load_model(f)
    model.eval()

    results = []
    local_video_loc = 'video_to_predict_{}.mp4'.format(get_uuid())

    for video_loc in video_locations:
        start = time.time()
        with open(video_loc, 'rb') as f_in:
            with builtins.open(local_video_loc, 'wb') as f_out:
                f_out.write(f_in.read())

        # Obtain video frames
        frames = extract_frames(local_video_loc, NUM_SEGMENTS)

        # Prepare input tensor [num_frames, 3, 224, 224]
        input_v = torch.stack([transform(frame) for frame in frames])

        # Make video prediction
        with torch.no_grad():
            logits = model(input_v)
            h_x = F.softmax(logits, 1).mean(dim=0)
            probs, idx = h_x.sort(0, True)

        # Output the prediction
        result = dict(key=video_loc)
        result['prediction'] = (idx[0], round(float(probs[0]), 5))
        result['iter_duration'] = time.time() - start
        results.append(result)
    queue.put(results)
</code></pre>

<pre class="codehilite"><code class="language-python">queue = Queue()
pool = Pool(initargs=initargs)

# Slice data keys
N = min(CONCURRENCY, len(video_locations))
iterable = [(queue, video_locations[n::CONCURRENCY]) 
            for n in range(N)]

# Map and reduce on the go
start = time.time()
r = pool.map_async(func=predict_videos, iterable=iterable)
pred_x_categ = reduce(queue, N)
end = time.time()

print('\nDone.')
print('Videos processed:', len(video_locations))
print('Total duration:', round(end - start, 2), 'sec\n')

for categ, count in pred_x_categ.items():
    if count != 0:
        print('{}: {}'.format(categ, count))
</code></pre>

<h4 id="clean">Clean<a class="headerlink" href="#clean" title="Permanent link">&para;</a></h4>
<pre class="codehilite"><code class="language-python">try:
    os.remove(weights_location)
except FileNotFoundError:
    pass

try:
    os.remove(WEIGHTS_FILE)
except FileNotFoundError:
    pass
</code></pre>

<h4 id="dockerfiles-and-build-scripts-for-both-runtimes-can-be-found-in-the-docker-folder">Dockerfiles and build scripts for both runtimes can be found in the docker/ folder.<a class="headerlink" href="#dockerfiles-and-build-scripts-for-both-runtimes-can-be-found-in-the-docker-folder" title="Permanent link">&para;</a></h4>
<h4 id="source-code-adapted-from-the-demonstration-in-httpsgithubcomzhouboleimoments_models">Source code adapted from the demonstration in https://github.com/zhoubolei/moments_models<a class="headerlink" href="#source-code-adapted-from-the-demonstration-in-httpsgithubcomzhouboleimoments_models" title="Permanent link">&para;</a></h4>
<h4 id="moments-in-time-article-httpmomentscsailmitedupaper">Moments in Time article: http://moments.csail.mit.edu/#paper<a class="headerlink" href="#moments-in-time-article-httpmomentscsailmitedupaper" title="Permanent link">&para;</a></h4>
              
            </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
      
    </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme.js" defer></script>
      <script src="../../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
